{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom datetime import datetime\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-26T17:10:51.917030Z","iopub.execute_input":"2023-02-26T17:10:51.917387Z","iopub.status.idle":"2023-02-26T17:10:51.929436Z","shell.execute_reply.started":"2023-02-26T17:10:51.917361Z","shell.execute_reply":"2023-02-26T17:10:51.927684Z"},"trusted":true},"execution_count":88,"outputs":[{"name":"stdout","text":"/kaggle/input/garanti-bbva-data-camp/work_experiences.csv\n/kaggle/input/garanti-bbva-data-camp/languages.csv\n/kaggle/input/garanti-bbva-data-camp/submission.csv\n/kaggle/input/garanti-bbva-data-camp/test_users.csv\n/kaggle/input/garanti-bbva-data-camp/skills.csv\n/kaggle/input/garanti-bbva-data-camp/train_users.csv\n/kaggle/input/garanti-bbva-data-camp/education.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Reading datas","metadata":{}},{"cell_type":"code","source":"train_users = pd.read_csv('/kaggle/input/garanti-bbva-data-camp/train_users.csv')\ntest_users = pd.read_csv('/kaggle/input/garanti-bbva-data-camp/test_users.csv')\nsubmission  = pd.read_csv('/kaggle/input/garanti-bbva-data-camp/submission.csv')\nwork_experiences = pd.read_csv('/kaggle/input/garanti-bbva-data-camp/work_experiences.csv')\nlanguages = pd.read_csv('/kaggle/input/garanti-bbva-data-camp/languages.csv')\nskills = pd.read_csv('/kaggle/input/garanti-bbva-data-camp/skills.csv')\neducation = pd.read_csv('/kaggle/input/garanti-bbva-data-camp/education.csv')","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:10:52.042223Z","iopub.execute_input":"2023-02-26T17:10:52.043136Z","iopub.status.idle":"2023-02-26T17:10:52.748523Z","shell.execute_reply.started":"2023-02-26T17:10:52.043099Z","shell.execute_reply":"2023-02-26T17:10:52.747164Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"#ana dataframe lerin indexleri user_id olarak ayarlandı\ntrain_users = train_users.set_index(\"user_id\")\ntest_users = test_users.set_index(\"user_id\")\nsubmission = submission.set_index(\"user_id\")","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:10:52.750634Z","iopub.execute_input":"2023-02-26T17:10:52.751235Z","iopub.status.idle":"2023-02-26T17:10:52.759539Z","shell.execute_reply.started":"2023-02-26T17:10:52.751207Z","shell.execute_reply":"2023-02-26T17:10:52.758350Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"def tr_eng(x):\n    x = x.str.upper()\n    tr_engs = str.maketrans(\"ÇĞİÖŞÜ\",\"CGIOSU\")\n    x = x.str.translate(tr_engs)\n    return x\n\ndef tr_eng_str(x):\n    x = x.upper()\n    tr_engs_str = str.maketrans(\"ÇĞİÖŞÜ\",\"CGIOSU\")\n    x = x.translate(tr_engs_str)\n    return x","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:10:52.760991Z","iopub.execute_input":"2023-02-26T17:10:52.761423Z","iopub.status.idle":"2023-02-26T17:10:52.772768Z","shell.execute_reply.started":"2023-02-26T17:10:52.761398Z","shell.execute_reply":"2023-02-26T17:10:52.771441Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"markdown","source":"## Editing user datas","metadata":{}},{"cell_type":"code","source":"df = pd.concat([train_users, test_users])\n\ndf['industry'] = tr_eng(df['industry'])\ndf['location'] = tr_eng(df['location'])\n\n\nsehirler=[\"Adana\", \"Adıyaman\", \"Afyon\", \"Ağrı\", \"Amasya\", \"Ankara\", \"Antalya\", \"Artvin\", \"Aydın\", \"Balıkesir\", \"Bilecik\", \"Bingöl\", \"Bitlis\", \"Bolu\", \"Burdur\", \"Bursa\", \"Çanakkale\", \"Çankırı\", \"Çorum\", \"Denizli\", \"Diyarbakır\", \"Edirne\", \"Elazığ\", \"Erzincan\", \"Erzurum\", \"Eskişehir\", \"Gaziantep\", \"Giresun\", \"Gümüşhane\", \"Hakkari\", \"Hatay\", \"Isparta\", \"İçel\", \"Mersin\", \"İstanbul\", \"İzmir\", \"Kars\", \"Kastamonu\", \"Kayseri\", \"Kırklareli\", \"Kırşehir\", \"Kocaeli\", \"Konya\", \"Kütahya\", \"Malatya\", \"Manisa\", \"Kahramanmaraş\", \"Mardin\", \"Muğla\", \"Muş\", \"Nevşehir\", \"Niğde\", \"Ordu\", \"Rize\", \"Sakarya\", \"Samsun\", \"Siirt\", \"Sinop\", \"Sivas\", \"Tekirdağ\", \"Tokat\", \"Trabzon\", \"Tunceli\", \"Şanlıurfa\", \"Uşak\", \"Van\", \"Yozgat\", \"Zonguldak\", \"Aksaray\", \"Bayburt\", \"Karaman\", \"Kırıkkale\", \"Batman\", \"Şırnak\", \"Bartın\", \"Ardahan\", \"Iğdır\", \"Yalova\", \"Karabük\", \"Kilis\", \"Osmaniye\", \"Düzce\"\n]\nulkeler = ['Afghanistan', 'Aland Islands', 'Albania', 'Algeria', 'American Samoa', 'Andorra', 'Angola', 'Anguilla', 'Antarctica', 'Antigua and Barbuda', 'Argentina', 'Armenia', 'Aruba', 'Australia', 'Austria', 'Azerbaijan', 'Bahamas', 'Bahrain', 'Bangladesh', 'Barbados', 'Belarus', 'Belgium', 'Belize', 'Benin', 'Bermuda', 'Bhutan', 'Bolivia, Plurinational State of', 'Bonaire, Sint Eustatius and Saba', 'Bosnia and Herzegovina', 'Botswana', 'Bouvet Island', 'Brazil', 'British Indian Ocean Territory', 'Brunei Darussalam', 'Bulgaria', 'Burkina Faso', 'Burundi', 'Cambodia', 'Cameroon', 'Canada', 'Cape Verde', 'Cayman Islands', 'Central African Republic', 'Chad', 'Chile', 'China', 'Christmas Island', 'Cocos (Keeling) Islands', 'Colombia', 'Comoros', 'Congo', 'Congo, The Democratic Republic of the', 'Cook Islands', 'Costa Rica', \"Côte d'Ivoire\", 'Croatia', 'Cuba', 'Curaçao', 'Cyprus', 'Czech Republic', 'Denmark', 'Djibouti', 'Dominica', 'Dominican Republic', 'Ecuador', 'Egypt', 'El Salvador', 'Equatorial Guinea', 'Eritrea', 'Estonia', 'Ethiopia', 'Falkland Islands (Malvinas)', 'Faroe Islands', 'Fiji', 'Finland', 'France', 'French Guiana', 'French Polynesia', 'French Southern Territories', 'Gabon', 'Gambia', 'Georgia', 'Germany', 'Ghana', 'Gibraltar', 'Greece', 'Greenland', 'Grenada', 'Guadeloupe', 'Guam', 'Guatemala', 'Guernsey', 'Guinea', 'Guinea-Bissau', 'Guyana', 'Haiti', 'Heard Island and McDonald Islands', 'Holy See (Vatican City State)', 'Honduras', 'Hong Kong', 'Hungary', 'Iceland', 'India', 'Indonesia', 'Iran, Islamic Republic of', 'Iraq', 'Ireland', 'Isle of Man', 'Israel', 'Italy', 'Jamaica', 'Japan', 'Jersey', 'Jordan', 'Kazakhstan', 'Kenya', 'Kiribati', \"Korea, Democratic People's Republic of\", 'Korea, Republic of', 'Kuwait', 'Kyrgyzstan', \"Lao People's Democratic Republic\", 'Latvia', 'Lebanon', 'Lesotho', 'Liberia', 'Libya', 'Liechtenstein', 'Lithuania', 'Luxembourg', 'Macao', 'Macedonia, Republic of', 'Madagascar', 'Malawi', 'Malaysia', 'Maldives', 'Mali', 'Malta', 'Marshall Islands', 'Martinique', 'Mauritania', 'Mauritius', 'Mayotte', 'Mexico', 'Micronesia, Federated States of', 'Moldova, Republic of', 'Monaco', 'Mongolia', 'Montenegro', 'Montserrat', 'Morocco', 'Mozambique', 'Myanmar', 'Namibia', 'Nauru', 'Nepal', 'Netherlands', 'New Caledonia', 'New Zealand', 'Nicaragua', 'Niger', 'Nigeria', 'Niue', 'Norfolk Island', 'Northern Mariana Islands', 'Norway', 'Oman', 'Pakistan', 'Palau', 'Palestinian Territory, Occupied', 'Panama', 'Papua New Guinea', 'Paraguay', 'Peru', 'Philippines', 'Pitcairn', 'Poland', 'Portugal', 'Puerto Rico', 'Qatar', 'Réunion', 'Romania', 'Russian Federation', 'Rwanda', 'Saint Barthélemy', 'Saint Helena, Ascension and Tristan da Cunha', 'Saint Kitts and Nevis', 'Saint Lucia', 'Saint Martin (French part)', 'Saint Pierre and Miquelon', 'Saint Vincent and the Grenadines', 'Samoa', 'San Marino', 'Sao Tome and Principe', 'Saudi Arabia', 'Senegal', 'Serbia', 'Seychelles', 'Sierra Leone', 'Singapore', 'Sint Maarten (Dutch part)', 'Slovakia', 'Slovenia', 'Solomon Islands', 'Somalia', 'South Africa', 'South Georgia and the South Sandwich Islands', 'Spain', 'Sri Lanka', 'Sudan', 'Suriname', 'South Sudan', 'Svalbard and Jan Mayen', 'Swaziland', 'Sweden', 'Switzerland', 'Syrian Arab Republic', 'Taiwan, Province of China', 'Tajikistan', 'Tanzania, United Republic of', 'Thailand', 'Timor-Leste', 'Togo', 'Tokelau', 'Tonga', 'Trinidad and Tobago', 'Tunisia', 'Turkey', 'Turkmenistan', 'Turks and Caicos Islands', 'Tuvalu', 'Uganda', 'Ukraine', 'United Arab Emirates', 'United Kingdom', 'United States', 'United States Minor Outlying Islands', 'Uruguay', 'Uzbekistan', 'Vanuatu', 'Venezuela, Bolivarian Republic of', 'Viet Nam', 'Virgin Islands, British', 'Virgin Islands, U.S.', 'Wallis and Futuna', 'Yemen', 'Zambia', 'Zimbabwe']\n\n\n\nfor i in sehirler:\n    i = tr_eng_str(i)\n    df.loc[df['location'].str.contains(i,na=False),'location'] = i\n    \n    \n    \nfor i in ulkeler:\n    i = tr_eng_str(i)\n    df.loc[df['location'].str.contains(i,na=False),'location'] = i\n\n    \n    \nlist = df['industry'].value_counts().index\n\nfor i in list:\n    df.loc[df['industry'].str.contains(i,na=False),'industry'] = i","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:10:52.775367Z","iopub.execute_input":"2023-02-26T17:10:52.775714Z","iopub.status.idle":"2023-02-26T17:11:08.144672Z","shell.execute_reply.started":"2023-02-26T17:10:52.775681Z","shell.execute_reply":"2023-02-26T17:11:08.142609Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"markdown","source":"## Editing Work Experiences","metadata":{}},{"cell_type":"code","source":"work_experiences.groupby('user_id', group_keys=False).apply(lambda x: x.sort_values(['start_year_month'], ascending=False).head(1)).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:11:08.146435Z","iopub.execute_input":"2023-02-26T17:11:08.147495Z","iopub.status.idle":"2023-02-26T17:11:40.556462Z","shell.execute_reply.started":"2023-02-26T17:11:08.147466Z","shell.execute_reply":"2023-02-26T17:11:40.554950Z"},"trusted":true},"execution_count":93,"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"       user_id  company_id            location  start_year_month\n0            0           0  Serbest Çalışmalar            200509\n1            2          10      Mersin, Turkey            201806\n2            5          15            İstanbul            201706\n3            7          20              Elazığ            201812\n4           10          26    Istanbul, Turkey            201805\n...        ...         ...                 ...               ...\n57074    66269         264    Istanbul, Turkey            201812\n57075    66270        4046   İstanbul, Türkiye            201812\n57076    66271        1495     Kocaeli, Turkey            201910\n57077    66272         944    Istanbul, Turkey            201812\n57078    66273        5863                 NaN            201910\n\n[57079 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>company_id</th>\n      <th>location</th>\n      <th>start_year_month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>Serbest Çalışmalar</td>\n      <td>200509</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>10</td>\n      <td>Mersin, Turkey</td>\n      <td>201806</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>15</td>\n      <td>İstanbul</td>\n      <td>201706</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n      <td>20</td>\n      <td>Elazığ</td>\n      <td>201812</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10</td>\n      <td>26</td>\n      <td>Istanbul, Turkey</td>\n      <td>201805</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>57074</th>\n      <td>66269</td>\n      <td>264</td>\n      <td>Istanbul, Turkey</td>\n      <td>201812</td>\n    </tr>\n    <tr>\n      <th>57075</th>\n      <td>66270</td>\n      <td>4046</td>\n      <td>İstanbul, Türkiye</td>\n      <td>201812</td>\n    </tr>\n    <tr>\n      <th>57076</th>\n      <td>66271</td>\n      <td>1495</td>\n      <td>Kocaeli, Turkey</td>\n      <td>201910</td>\n    </tr>\n    <tr>\n      <th>57077</th>\n      <td>66272</td>\n      <td>944</td>\n      <td>Istanbul, Turkey</td>\n      <td>201812</td>\n    </tr>\n    <tr>\n      <th>57078</th>\n      <td>66273</td>\n      <td>5863</td>\n      <td>NaN</td>\n      <td>201910</td>\n    </tr>\n  </tbody>\n</table>\n<p>57079 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"work_experiences['start_year_month'] = work_experiences['start_year_month'].map(str)\nwork_experiences = work_experiences[~work_experiences[\"start_year_month\"].str.contains(\"2019\")]\n\nwork_experiences['start_year_month'] = pd.to_datetime(work_experiences['start_year_month'].astype(str), format='%Y%m')\n\nworks = work_experiences.groupby([\"user_id\"])\nwork = works.agg(minimum_date = ('start_year_month', np.min), maximum_date = ('start_year_month', np.max))\n\nwork_experiences.drop(['location','company_id'], inplace=True, axis=1)\nwork_exp = work_experiences.groupby(['user_id']).count()\n\nwork_experiences = pd.merge(work_exp,work, on=\"user_id\")","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:11:40.558032Z","iopub.execute_input":"2023-02-26T17:11:40.558283Z","iopub.status.idle":"2023-02-26T17:11:40.847039Z","shell.execute_reply.started":"2023-02-26T17:11:40.558259Z","shell.execute_reply":"2023-02-26T17:11:40.845293Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"#Let's calculate the total working month of people\n\nwork_experiences['work_exp'] = (datetime.strptime('01-01-2019', '%m-%d-%Y') - work_experiences['minimum_date'])/30\nwork_experiences['work_exp'] = work_experiences['work_exp'].map(str)\nnew = work_experiences['work_exp'].str.split(\" \", n = 1, expand = True)\nwork_experiences['work_exp'] = new[0]\n\n#Let's calculate the total working time of people in their last workplace\n\nwork_experiences['last_date'] = (datetime.strptime('01-01-2019', '%m-%d-%Y') - work_experiences['maximum_date'])/30\nwork_experiences['last_date'] = work_experiences['last_date'].map(str)\nnew1 = work_experiences['last_date'].str.split(\" \", n = 1, expand = True)\nwork_experiences['last_date'] = new1[0]\n","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:11:40.849157Z","iopub.execute_input":"2023-02-26T17:11:40.850020Z","iopub.status.idle":"2023-02-26T17:11:42.235753Z","shell.execute_reply.started":"2023-02-26T17:11:40.849963Z","shell.execute_reply":"2023-02-26T17:11:42.234364Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"work_experiences['numbers_work_change'] = work_experiences['start_year_month']\nwork_experiences.drop(['start_year_month','minimum_date','maximum_date'], inplace=True, axis=1)\n\n\nwork_experiences['work_change_ratio'] = work_experiences['work_exp'].astype(int) / work_experiences['numbers_work_change'].astype(int)\nwork_experiences['work_change_ratio'] = work_experiences['work_change_ratio'] / work_experiences['work_change_ratio'].max()\n","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:11:42.239357Z","iopub.execute_input":"2023-02-26T17:11:42.239709Z","iopub.status.idle":"2023-02-26T17:11:42.268107Z","shell.execute_reply.started":"2023-02-26T17:11:42.239685Z","shell.execute_reply":"2023-02-26T17:11:42.266583Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"work_experiences","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:11:42.269859Z","iopub.execute_input":"2023-02-26T17:11:42.270170Z","iopub.status.idle":"2023-02-26T17:11:42.287420Z","shell.execute_reply.started":"2023-02-26T17:11:42.270145Z","shell.execute_reply":"2023-02-26T17:11:42.285788Z"},"trusted":true},"execution_count":97,"outputs":[{"execution_count":97,"output_type":"execute_result","data":{"text/plain":"        work_exp last_date  numbers_work_change  work_change_ratio\nuser_id                                                           \n0            162       162                    2           0.130645\n2             25         7                    3           0.013441\n5             19        19                    1           0.030645\n7             30         1                    4           0.012097\n10            65         8                    3           0.034946\n...          ...       ...                  ...                ...\n66269        179         1                    5           0.057742\n66270         50         1                    2           0.040323\n66271        209        26                    9           0.037455\n66272         79         1                    5           0.025484\n66273         55         3                    8           0.011089\n\n[53002 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>work_exp</th>\n      <th>last_date</th>\n      <th>numbers_work_change</th>\n      <th>work_change_ratio</th>\n    </tr>\n    <tr>\n      <th>user_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>162</td>\n      <td>162</td>\n      <td>2</td>\n      <td>0.130645</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>25</td>\n      <td>7</td>\n      <td>3</td>\n      <td>0.013441</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>19</td>\n      <td>19</td>\n      <td>1</td>\n      <td>0.030645</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>30</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0.012097</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>65</td>\n      <td>8</td>\n      <td>3</td>\n      <td>0.034946</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>66269</th>\n      <td>179</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0.057742</td>\n    </tr>\n    <tr>\n      <th>66270</th>\n      <td>50</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.040323</td>\n    </tr>\n    <tr>\n      <th>66271</th>\n      <td>209</td>\n      <td>26</td>\n      <td>9</td>\n      <td>0.037455</td>\n    </tr>\n    <tr>\n      <th>66272</th>\n      <td>79</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0.025484</td>\n    </tr>\n    <tr>\n      <th>66273</th>\n      <td>55</td>\n      <td>3</td>\n      <td>8</td>\n      <td>0.011089</td>\n    </tr>\n  </tbody>\n</table>\n<p>53002 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Editing Languages","metadata":{}},{"cell_type":"code","source":"lang_rank = {\n    'elementary': 1,\n    'limited_working': 2,\n    'professional_working': 3,\n    'full_professional': 4,\n    'native_or_bilingual': 5\n}\n\n\nlanguages.loc[:, 'proficiency'] = languages.loc[:, 'proficiency'].map(lang_rank)","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:11:42.288915Z","iopub.execute_input":"2023-02-26T17:11:42.289304Z","iopub.status.idle":"2023-02-26T17:11:42.308569Z","shell.execute_reply.started":"2023-02-26T17:11:42.289269Z","shell.execute_reply":"2023-02-26T17:11:42.306815Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"lang = languages[languages['language'].notnull() & languages['proficiency'].notnull()]\n\nlang['language'] = tr_eng(lang['language'])\n\n\nlang_conv = {\n    '(?i).*(ENGLISH|ENGLISHCH|ENGLISCH|ING|INGILICE|INGILIZ|INGILIZE|INGILIZICE|INGILILIZCE|INGLIZCE|INGILIZCE).*': 'ENGLISH',\n    '(?i).*(ALMANCA|GERMAN|DEUTSCH).*': 'GERMAN',\n    '(?i).*(FRANSIZCA|FRENCH|FRANCAIS|FRANCE|FRANSIZ|FRANZOSISCH).*': 'FRENCH',\n    '(?i).*(ISPANYOLCA|SPANISH|ESPAÑOL|ESPANOL|SPANI).*': 'SPANISH',\n    '(?i).*(ARAPCA|ARABIC|ARABISH).*': 'ARABIC',\n    '(?i).*(RUSCA|RUSSIAN|RUSSE).*': 'RUSSAIN',\n    '(?i).*(TURKCE|TURKISH|TURKISCH|TURK|TURKCE).*': 'TURKISH',\n    '(?i).*(ITALIAN|ITALYANCA|ITALIANO|ITALIEN).*': 'ITALIAN',\n    '(?i).*(JAPANESE|JAPONCA).*': 'JAPANESE',\n}\n\nlang['language'] = lang['language'].replace(lang_conv, regex=True)\nlang = lang[lang['language'].isin(lang_conv.values())]\n\n#lang_used = lang['language'].value_counts().iloc[:5].index\n#lang = lang[lang['language'].isin(lang_used)]\n\nlang = lang.drop_duplicates(['user_id', 'language'])\nlang = pd.pivot(lang, index='user_id', columns='language', values='proficiency')\nlang = lang.fillna(0).astype(int)\nlang","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:11:42.310454Z","iopub.execute_input":"2023-02-26T17:11:42.310836Z","iopub.status.idle":"2023-02-26T17:11:44.260665Z","shell.execute_reply.started":"2023-02-26T17:11:42.310805Z","shell.execute_reply":"2023-02-26T17:11:44.258863Z"},"trusted":true},"execution_count":99,"outputs":[{"execution_count":99,"output_type":"execute_result","data":{"text/plain":"language  ARABIC  ENGLISH  FRENCH  GERMAN  ITALIAN  JAPANESE  RUSSAIN  \\\nuser_id                                                                 \n8              0        4       1       0        0         0        0   \n11             0        3       0       0        0         0        0   \n12             0        3       0       0        0         0        0   \n13             0        4       0       2        0         0        0   \n14             0        3       0       0        0         0        0   \n...          ...      ...     ...     ...      ...       ...      ...   \n66254          0        4       1       3        0         0        0   \n66255          0        3       0       1        0         0        0   \n66262          0        4       0       0        0         0        0   \n66272          0        3       0       0        0         0        0   \n66273          0        3       0       1        0         0        0   \n\nlanguage  SPANISH  TURKISH  \nuser_id                     \n8               0        5  \n11              0        5  \n12              0        5  \n13              0        0  \n14              0        5  \n...           ...      ...  \n66254           1        0  \n66255           0        5  \n66262           0        0  \n66272           0        0  \n66273           0        5  \n\n[31012 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>language</th>\n      <th>ARABIC</th>\n      <th>ENGLISH</th>\n      <th>FRENCH</th>\n      <th>GERMAN</th>\n      <th>ITALIAN</th>\n      <th>JAPANESE</th>\n      <th>RUSSAIN</th>\n      <th>SPANISH</th>\n      <th>TURKISH</th>\n    </tr>\n    <tr>\n      <th>user_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>66254</th>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>66255</th>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>66262</th>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>66272</th>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>66273</th>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>31012 rows × 9 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"lang_point = languages.groupby(['user_id']).agg({'proficiency':sum})\n\nlanguages = languages.groupby(['user_id']).count()\nlanguages.drop(['proficiency'], inplace=True, axis=1)\nlanguages.rename(columns = {'language':'numbers_of_languages'}, inplace=True)\nlanguages = languages.merge(lang_point, how='inner', on = ['user_id'])\nlanguages","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:11:44.262445Z","iopub.execute_input":"2023-02-26T17:11:44.262786Z","iopub.status.idle":"2023-02-26T17:11:44.306889Z","shell.execute_reply.started":"2023-02-26T17:11:44.262760Z","shell.execute_reply":"2023-02-26T17:11:44.305089Z"},"trusted":true},"execution_count":100,"outputs":[{"execution_count":100,"output_type":"execute_result","data":{"text/plain":"         numbers_of_languages  proficiency\nuser_id                                   \n8                           3         10.0\n10                          1          0.0\n11                          3         13.0\n12                          2          8.0\n13                          2          6.0\n...                       ...          ...\n66265                       1          0.0\n66269                       1          0.0\n66271                       1          0.0\n66272                       1          3.0\n66273                       3          9.0\n\n[37290 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>numbers_of_languages</th>\n      <th>proficiency</th>\n    </tr>\n    <tr>\n      <th>user_id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8</th>\n      <td>3</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>3</td>\n      <td>13.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>2</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>2</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>66265</th>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>66269</th>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>66271</th>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>66272</th>\n      <td>1</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>66273</th>\n      <td>3</td>\n      <td>9.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>37290 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Editing Skills Data","metadata":{}},{"cell_type":"code","source":"skills = pd.read_csv('/kaggle/input/garanti-bbva-data-camp/skills.csv')","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:11:44.308828Z","iopub.execute_input":"2023-02-26T17:11:44.309203Z","iopub.status.idle":"2023-02-26T17:11:44.698345Z","shell.execute_reply.started":"2023-02-26T17:11:44.309177Z","shell.execute_reply":"2023-02-26T17:11:44.696943Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"skills['skill'] = tr_eng(skills['skill'])\n\nused_skills = skills['skill'].value_counts().iloc[:20].index # we only took most common 20 skills, you can increase it\n\nskill = skills[skills['skill'].isin(used_skills)]\nskill['experience'] = True\n\nskill = skill.drop_duplicates(['user_id', 'skill'])\nskill = pd.pivot(skill, index='user_id', columns='skill', values='experience')\nskill = skill.fillna(0).astype(int)\nskill.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:11:44.699789Z","iopub.execute_input":"2023-02-26T17:11:44.700973Z","iopub.status.idle":"2023-02-26T17:11:47.574741Z","shell.execute_reply.started":"2023-02-26T17:11:44.700911Z","shell.execute_reply":"2023-02-26T17:11:47.573440Z"},"trusted":true},"execution_count":102,"outputs":[{"execution_count":102,"output_type":"execute_result","data":{"text/plain":"skill    .NET  ASP.NET  ASP.NET MVC  C  C#  C++  CSS  GIT  HTML  HTML5  JAVA  \\\nuser_id                                                                        \n2           0        0            0  0   0    0    0    0     0      0     1   \n7           0        0            0  0   0    0    0    0     0      0     1   \n10          0        0            0  0   0    0    0    0     0      0     1   \n11          0        0            0  1   1    0    1    1     1      0     1   \n12          0        0            0  0   0    0    1    0     1      0     1   \n\nskill    JAVASCRIPT  JQUERY  LINUX  MICROSOFT OFFICE  MICROSOFT SQL SERVER  \\\nuser_id                                                                      \n2                 0       0      0                 1                     0   \n7                 1       0      0                 0                     0   \n10                0       0      0                 0                     0   \n11                1       0      1                 0                     1   \n12                1       0      0                 0                     1   \n\nskill    MYSQL  PYTHON  SOFTWARE DEVELOPMENT  SQL  \nuser_id                                            \n2            0       0                     0    0  \n7            1       0                     0    1  \n10           0       0                     0    0  \n11           1       1                     1    1  \n12           1       0                     0    1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>skill</th>\n      <th>.NET</th>\n      <th>ASP.NET</th>\n      <th>ASP.NET MVC</th>\n      <th>C</th>\n      <th>C#</th>\n      <th>C++</th>\n      <th>CSS</th>\n      <th>GIT</th>\n      <th>HTML</th>\n      <th>HTML5</th>\n      <th>JAVA</th>\n      <th>JAVASCRIPT</th>\n      <th>JQUERY</th>\n      <th>LINUX</th>\n      <th>MICROSOFT OFFICE</th>\n      <th>MICROSOFT SQL SERVER</th>\n      <th>MYSQL</th>\n      <th>PYTHON</th>\n      <th>SOFTWARE DEVELOPMENT</th>\n      <th>SQL</th>\n    </tr>\n    <tr>\n      <th>user_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"skills = skills.groupby(['user_id']).count()\nskills.rename(columns = {'skill':'numbers_of_skills'}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:11:47.576166Z","iopub.execute_input":"2023-02-26T17:11:47.576505Z","iopub.status.idle":"2023-02-26T17:11:47.687603Z","shell.execute_reply.started":"2023-02-26T17:11:47.576479Z","shell.execute_reply":"2023-02-26T17:11:47.686900Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"markdown","source":"## Editing Education Datas","metadata":{}},{"cell_type":"code","source":"education = pd.read_csv('/kaggle/input/garanti-bbva-data-camp/education.csv')","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:11:47.688976Z","iopub.execute_input":"2023-02-26T17:11:47.689870Z","iopub.status.idle":"2023-02-26T17:11:47.834565Z","shell.execute_reply.started":"2023-02-26T17:11:47.689824Z","shell.execute_reply":"2023-02-26T17:11:47.833907Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"education = education[education['school_name'].notnull() & education['degree'].notnull()]\n\n\neducation['school_name'] = tr_eng(education['school_name'])\n\n\nuni_list = [\"ORTA DOGU TEKNIK UNIVERSITESI\",\"YILDIZ TEKNIK UNIVERSITESI\",\"GEBZE TEKNIK UNIVERSITESI\",\"ISTANBUL TEKNIK UNIVERSITESI\",\"KARADENIZ TEKNIK UNIVERSITESI\",\"KARADENIZ TECHNICAL UNIVERSITY\",\"ESKISEHIR TEKNIK UNIVERSITESI\",\"DOGU AKDENIZ UNIVERSITESI\",\"BOGAZICI UNIVERSITESI / BOGAZICI UNIVERSITY\"]\nnew_uni_list = [\"MIDDLE EAST TECHNICAL UNIVERSITY\",\"YILDIZ TECHNICAL UNIVERSITY\",\"GEBZE TECHNICAL UNIVERSITY\",\"ISTANBUL TECHNICAL UNIVERSITY\",\"BLACKSEA TECHNICAL UNIVERSITY\",\"BLACKSEA TECHNICAL UNIVERSITY\",\"ESKISEHIR TECHNICAL UNIVERSITY\",\"EASTERN MEDITERRANEAN UNIVERSITY\",\"BOGAZICI UNIVERSITY\"]\n\nc = 0\nfor i in uni_list:\n    education.loc[education['school_name'].str.contains(i,na=False),'school_name'] = new_uni_list[c]\n    c += 1\n    \neducation['school_name'] = education['school_name'].str.replace('UNIVERSITESI', 'UNIVERSITY')\n\neducation = education[education[\"school_name\"].str.contains(\"UNIVERSITY\")]\n","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:11:47.835677Z","iopub.execute_input":"2023-02-26T17:11:47.836404Z","iopub.status.idle":"2023-02-26T17:11:48.977518Z","shell.execute_reply.started":"2023-02-26T17:11:47.836370Z","shell.execute_reply":"2023-02-26T17:11:48.973596Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"education['degree'] = tr_eng(education['degree'])\n\n\nlist_lisans = [\"Bachelor of Science (B.Sc.)\",\"Engineer's degree\",\"Lisans \",\"Lisans Derecesi\",\"Bachelor's degree\",\"Lisans\",\"Bachelor of Science - BS\",\"Bachelor of Science (BS)\",\"Bachelor of Engineering - BE\",\"Bachelor of Science (BSc)\",\"Licentiate degree\",\"Bachelor's Degree\",\"Mühendislik Fakültesi Mezunu\",\"Mühendislik Fakültesi\",\"Bachelor’s Degree\",\"BS\",\"Bachelor of Engineering (B.E.)\",\"Bachelor of Science (B.S.)\",\"lisans\",\"Bachelor of Engineering (B.Eng.)\",\"Bachelor of Business Administration - BBA\",\"BSc\",\"İşletme Fakültesi\",\"Bachelor of Engineering (BEng)\",\"Lisans\",\"İşletme Fakültesi Mezunu\",\"Bachelor of Business Administration (B.B.A.)\"]\nlist_onlisans = [\"Önlisans\",\"Ön Lisans\",\"Associate's degree\",\"Yüksekokul Mezunu\",\"Ön lisans\",\"önlisans\"]\nlist_yukseklisans = [\"Yüksek Lisans (Master)\",\"Master's degree\",\"Master of Science - MS\",\"İşletme Yüksek Lisans Programı (MBA)\",\"Master of Science (MSc)\",\"Master of Science (M.Sc.)\",\"Master of Business Administration - MBA\",\"Master’s Degree\",\"Master of Business Administration (M.B.A.)\",\"Master of Business Administration (MBA)\",\"Master's Degree\",\"Yüksek Lisans\",\"Master of Science (MS)\",\"Master of Engineering - MEng\",\"Master\",\"MSc\",\"Master of Science (M.S.)\"]\nlist_doktora = [\"Doctor of Philosophy - PhD\",\"Doctor of Philosophy (Ph.D.)\",\"Doktora (Dr.)\",\"Doctor of Philosophy (PhD)\"]\n\n#for i in list_yukseklisans:\n#education = education.loc[\"degree\"].replace(to_replace = \"Lisans Derecesi\", value = \"3\")\n\n        \nfor i in list_onlisans:\n    i = tr_eng_str(i)\n    education.loc[education[\"degree\"] == i,['degree']] = 'ASSOCIATE'\n    \nfor i in list_yukseklisans:\n    i = tr_eng_str(i)\n    education.loc[education[\"degree\"] == i,['degree']] = 'MASTER'\n    \nfor i in list_lisans:\n    i = tr_eng_str(i)\n    education.loc[education[\"degree\"] == i,['degree']] = 'BACHELOR'\n\nfor i in list_doktora:\n    i = tr_eng_str(i)\n    education.loc[education[\"degree\"] == i,['degree']] = 'PHD'\n\nedu = ['ASSOCIATE','BACHELOR','MASTER','PHD']\neducation = education[education['degree'].isin(edu)]","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:11:48.982338Z","iopub.execute_input":"2023-02-26T17:11:48.984135Z","iopub.status.idle":"2023-02-26T17:11:49.895865Z","shell.execute_reply.started":"2023-02-26T17:11:48.984076Z","shell.execute_reply":"2023-02-26T17:11:49.894283Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"educations = education\n\neducations = educations.drop_duplicates(['user_id', 'degree'])\n\neducations = educations.drop_duplicates(['user_id', 'degree'])\neducations = pd.pivot(educations, index='user_id', columns='degree', values='school_name')\n","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:11:49.902201Z","iopub.execute_input":"2023-02-26T17:11:49.902608Z","iopub.status.idle":"2023-02-26T17:11:49.989262Z","shell.execute_reply.started":"2023-02-26T17:11:49.902578Z","shell.execute_reply":"2023-02-26T17:11:49.987758Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"education.drop(['degree','fields_of_study','start_year_month','end_year_month'], inplace=True, axis=1)\n\neducation = education.groupby(['user_id']).count()\neducation.rename(columns = {'school_name':'numbers_of_schools'}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:11:49.990430Z","iopub.execute_input":"2023-02-26T17:11:49.990843Z","iopub.status.idle":"2023-02-26T17:11:50.023689Z","shell.execute_reply.started":"2023-02-26T17:11:49.990815Z","shell.execute_reply":"2023-02-26T17:11:50.022558Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"df = df.merge(work_experiences, how='left', on = ['user_id']).merge(skills, how='left', on = ['user_id']).merge(skill, how='left', on = ['user_id']).merge(lang, how='left', on = ['user_id']).merge(languages, how='left', on = ['user_id']).merge(education, how='left', on = ['user_id']).merge(educations, how='left', on = ['user_id'])","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:11:50.025112Z","iopub.execute_input":"2023-02-26T17:11:50.025500Z","iopub.status.idle":"2023-02-26T17:11:50.258613Z","shell.execute_reply.started":"2023-02-26T17:11:50.025467Z","shell.execute_reply":"2023-02-26T17:11:50.256838Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:11:50.260473Z","iopub.execute_input":"2023-02-26T17:11:50.260813Z","iopub.status.idle":"2023-02-26T17:11:50.324402Z","shell.execute_reply.started":"2023-02-26T17:11:50.260788Z","shell.execute_reply":"2023-02-26T17:11:50.322939Z"},"trusted":true},"execution_count":110,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 66274 entries, 1301 to 16036\nData columns (total 44 columns):\n #   Column                Non-Null Count  Dtype  \n---  ------                --------------  -----  \n 0   industry              66186 non-null  object \n 1   location              66273 non-null  object \n 2   moved_after_2019      53019 non-null  float64\n 3   work_exp              53002 non-null  object \n 4   last_date             53002 non-null  object \n 5   numbers_work_change   53002 non-null  float64\n 6   work_change_ratio     53002 non-null  float64\n 7   numbers_of_skills     62402 non-null  float64\n 8   .NET                  53554 non-null  float64\n 9   ASP.NET               53554 non-null  float64\n 10  ASP.NET MVC           53554 non-null  float64\n 11  C                     53554 non-null  float64\n 12  C#                    53554 non-null  float64\n 13  C++                   53554 non-null  float64\n 14  CSS                   53554 non-null  float64\n 15  GIT                   53554 non-null  float64\n 16  HTML                  53554 non-null  float64\n 17  HTML5                 53554 non-null  float64\n 18  JAVA                  53554 non-null  float64\n 19  JAVASCRIPT            53554 non-null  float64\n 20  JQUERY                53554 non-null  float64\n 21  LINUX                 53554 non-null  float64\n 22  MICROSOFT OFFICE      53554 non-null  float64\n 23  MICROSOFT SQL SERVER  53554 non-null  float64\n 24  MYSQL                 53554 non-null  float64\n 25  PYTHON                53554 non-null  float64\n 26  SOFTWARE DEVELOPMENT  53554 non-null  float64\n 27  SQL                   53554 non-null  float64\n 28  ARABIC                31012 non-null  float64\n 29  ENGLISH               31012 non-null  float64\n 30  FRENCH                31012 non-null  float64\n 31  GERMAN                31012 non-null  float64\n 32  ITALIAN               31012 non-null  float64\n 33  JAPANESE              31012 non-null  float64\n 34  RUSSAIN               31012 non-null  float64\n 35  SPANISH               31012 non-null  float64\n 36  TURKISH               31012 non-null  float64\n 37  numbers_of_languages  37290 non-null  float64\n 38  proficiency           37290 non-null  float64\n 39  numbers_of_schools    48051 non-null  float64\n 40  ASSOCIATE             4306 non-null   object \n 41  BACHELOR              42351 non-null  object \n 42  MASTER                16315 non-null  object \n 43  PHD                   1923 non-null   object \ndtypes: float64(36), object(8)\nmemory usage: 22.8+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"df['numbers_of_schools'].fillna(1, inplace=True)\ndf['numbers_of_languages'].fillna(1, inplace=True)\ndf['work_change_ratio'].fillna(1, inplace=True)\ndf['numbers_work_change'].fillna(1, inplace=True)\ndf['work_exp'].fillna(0, inplace=True)\n\n\nmean_value=df['numbers_of_skills'].mean()\ndf['numbers_of_skills'].fillna(value=mean_value, inplace=True)\n\n\nlista = [col for col in df.columns if df[col].isna().any()==True]\nlista = lista[3:-4]\n\ndf[lista] = df[lista].fillna(-1)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:11:50.326061Z","iopub.execute_input":"2023-02-26T17:11:50.326458Z","iopub.status.idle":"2023-02-26T17:11:50.447212Z","shell.execute_reply.started":"2023-02-26T17:11:50.326432Z","shell.execute_reply":"2023-02-26T17:11:50.445818Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"df['location'].nunique()","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:11:50.449039Z","iopub.execute_input":"2023-02-26T17:11:50.449397Z","iopub.status.idle":"2023-02-26T17:11:50.460852Z","shell.execute_reply.started":"2023-02-26T17:11:50.449371Z","shell.execute_reply":"2023-02-26T17:11:50.458968Z"},"trusted":true},"execution_count":112,"outputs":[{"execution_count":112,"output_type":"execute_result","data":{"text/plain":"96"},"metadata":{}}]},{"cell_type":"code","source":"# Import Label Encoder and train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\nencoder = LabelEncoder()\n\n# Encode the features to integers inside a for loop\n#for i in x.columns:\ndf['industry'] = encoder.fit_transform(df['industry'])\ndf['location'] = encoder.fit_transform(df['location'])\ndf['ASSOCIATE'] = encoder.fit_transform(df['ASSOCIATE'])\ndf['BACHELOR'] = encoder.fit_transform(df['BACHELOR'])\ndf['MASTER'] = encoder.fit_transform(df['MASTER'])\ndf['PHD'] = encoder.fit_transform(df['PHD'])","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:11:50.463109Z","iopub.execute_input":"2023-02-26T17:11:50.463509Z","iopub.status.idle":"2023-02-26T17:11:50.628952Z","shell.execute_reply.started":"2023-02-26T17:11:50.463474Z","shell.execute_reply":"2023-02-26T17:11:50.627092Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"df_train = df[df['moved_after_2019'].notnull()]\n\nlist = ['moved_after_2019','work_exp','last_date']\n\nfor i in list:\n    \n    df_train[i] = df_train[i].astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:11:50.629909Z","iopub.execute_input":"2023-02-26T17:11:50.630140Z","iopub.status.idle":"2023-02-26T17:11:50.672498Z","shell.execute_reply.started":"2023-02-26T17:11:50.630117Z","shell.execute_reply":"2023-02-26T17:11:50.671263Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"# Import Logistic Regression, Ridge Classifier, Decision Tree\n# Gaussian Naive Bayes, MLP Classifier and Random Forest models\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn import svm\nfrom sklearn.neighbors import KNeighborsClassifier\n\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\n\n\nfrom warnings import filterwarnings\nfilterwarnings('ignore')\n\n# Import Classification Report function\nfrom sklearn.metrics import classification_report","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:11:50.673958Z","iopub.execute_input":"2023-02-26T17:11:50.674333Z","iopub.status.idle":"2023-02-26T17:11:50.682378Z","shell.execute_reply.started":"2023-02-26T17:11:50.674309Z","shell.execute_reply":"2023-02-26T17:11:50.680561Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"# Create the X variable for features\nx = df_train.loc[:, [col for col in df_train.columns.values if col != 'moved_after_2019']]\n\n# Create the y variable for output labels\ny = df_train.loc[:,'moved_after_2019']\n\n\n# Encode the ouput labels to integers\ny = encoder.fit_transform(y)","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:11:50.684015Z","iopub.execute_input":"2023-02-26T17:11:50.684349Z","iopub.status.idle":"2023-02-26T17:11:50.705146Z","shell.execute_reply.started":"2023-02-26T17:11:50.684322Z","shell.execute_reply":"2023-02-26T17:11:50.703700Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"# Split the dataset into train and test sets with 70-30 ratio\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n\n# Create an object using the LogisticRegression() class\nlogistic_classifier_model = LogisticRegression()\n\n# Create an object using the RidgeClassifier() class\nridge_classifier_model = RidgeClassifier()\n\n# Create an object using the DecisionTreeClassifier() class\ndecision_tree_model = DecisionTreeClassifier()\n\n# Create an object using the GaussianNB() class\nnaive_bayes_model = GaussianNB()\n\n# Create an object using the MLPClassifier() class\nneural_network_model = MLPClassifier()\n\nsvm = svm.SVC()\n\nknn = KNeighborsClassifier(n_neighbors=3)\n\nxgboost_model = XGBClassifier()\n\ngb_model = GradientBoostingClassifier()\n\nrf_model = RandomForestClassifier()","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:11:50.706332Z","iopub.execute_input":"2023-02-26T17:11:50.706780Z","iopub.status.idle":"2023-02-26T17:11:50.737202Z","shell.execute_reply.started":"2023-02-26T17:11:50.706746Z","shell.execute_reply":"2023-02-26T17:11:50.735885Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"# Train the Logistic Classifier model\nlogistic_classifier_model.fit(x_train, y_train)\n\n# Train the Ridge Classifier model\nridge_classifier_model.fit(x_train, y_train)\n\n# Train the Decision Tree model\ndecision_tree_model.fit(x_train, y_train)\n\n# Train the Naive Bayes model\nnaive_bayes_model.fit(x_train, y_train)\n\n# Train the Neural Network model\nneural_network_model.fit(x_train, y_train)\n\nsvm.fit(x_train, y_train)\n\nknn.fit(x_train, y_train)\n\nxgboost_model.fit(x_train, y_train)\n\ngb_model.fit(x_train, y_train)\n\nrf_model.fit(x_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:11:50.738604Z","iopub.execute_input":"2023-02-26T17:11:50.738966Z","iopub.status.idle":"2023-02-26T17:14:58.677997Z","shell.execute_reply.started":"2023-02-26T17:11:50.738934Z","shell.execute_reply":"2023-02-26T17:14:58.676054Z"},"trusted":true},"execution_count":118,"outputs":[{"execution_count":118,"output_type":"execute_result","data":{"text/plain":"RandomForestClassifier()"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn import neural_network\n# Make prediction using the test dataset on Logistic Classifier model\nlogistic_pred = logistic_classifier_model.predict(x_test)\n\n# Make prediction using the test dataset on Ridge Classifier model\nridge_pred = ridge_classifier_model.predict(x_test)\n\n# Make prediction using the test dataset on Decision Tree model\ntree_pred = decision_tree_model.predict(x_test)\n\n# Make prediction using the test dataset on Naive Bayes model\nnaive_bayes_pred = naive_bayes_model.predict(x_test)\n\n# Make prediction using the test dataset on Neural Network model\nneural_network_pred = neural_network_model.predict(x_test)\n\nsvm_pred = svm.predict(x_test)\n\nknn_pred = knn.predict(x_test)\n\nxgboost_pred = xgboost_model.predict(x_test)\n\ngb_model_pred = gb_model.predict(x_test)\n\nrf_model_pred = rf_model.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:14:58.679982Z","iopub.execute_input":"2023-02-26T17:14:58.680422Z","iopub.status.idle":"2023-02-26T17:15:48.769166Z","shell.execute_reply.started":"2023-02-26T17:14:58.680383Z","shell.execute_reply":"2023-02-26T17:15:48.767829Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"# Create a Classification Report for Logistic Classifier model\nlogistic_report = classification_report(y_test, logistic_pred)\n\n# Create a Classification Report for Ridge Classifier model\nridge_report = classification_report(y_test, ridge_pred)\n\n# Create a Classification Report for Decision Tree model\ntree_report = classification_report(y_test, tree_pred)\n\n# Create a Classification Report for Naive Bayes model\nnaive_bayes_report = classification_report(y_test, naive_bayes_pred)\n\n# Create a Classification Report for Neural Network model\nneural_network_report = classification_report(y_test, neural_network_pred)\n\nsvm_report = classification_report(y_test, svm_pred)\n\nknn_report = classification_report(y_test, knn_pred)\n\nxgboost_report = classification_report(y_test, xgboost_pred)\n\ngb_model_report = classification_report(y_test, gb_model_pred)\n\nrf_model_report = classification_report(y_test, rf_model_pred)","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:15:48.770495Z","iopub.execute_input":"2023-02-26T17:15:48.770900Z","iopub.status.idle":"2023-02-26T17:15:48.996405Z","shell.execute_reply.started":"2023-02-26T17:15:48.770868Z","shell.execute_reply":"2023-02-26T17:15:48.995262Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"# Print the report of the Logistic Regression model\nprint('***** Logistic Regression *****')\nprint(logistic_report)\n# Print the report of the Ridge Regression model\nprint('***** Ridge Regression *****')\nprint(ridge_report)\n# Print the report of the Decision Tree model\nprint('***** Decision Tree *****')\nprint(tree_report)\n# Print the report of the Naive Bayes model\nprint('***** Naive Bayes *****')\nprint(naive_bayes_report)\n# Print the report of the Neural Network model\nprint('***** Neural Network *****')\nprint(neural_network_report)\n\nprint('***** XGBClassifier *****')\nprint(xgboost_report)\n\nprint('***** Support Vector Machines *****')\nprint(svm_report)\n\nprint('***** KNeighborsClassifier *****')\nprint(knn_report)\n\nprint('***** GradientBoostingClassifier *****')\nprint(gb_model_report)\n\nprint('***** RandomForestClassifier *****')\nprint(rf_model_report)","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:15:48.997785Z","iopub.execute_input":"2023-02-26T17:15:48.998101Z","iopub.status.idle":"2023-02-26T17:15:49.006823Z","shell.execute_reply.started":"2023-02-26T17:15:48.998076Z","shell.execute_reply":"2023-02-26T17:15:49.005501Z"},"trusted":true},"execution_count":121,"outputs":[{"name":"stdout","text":"***** Logistic Regression *****\n              precision    recall  f1-score   support\n\n           0       0.63      0.92      0.75      9661\n           1       0.56      0.16      0.25      6245\n\n    accuracy                           0.62     15906\n   macro avg       0.60      0.54      0.50     15906\nweighted avg       0.60      0.62      0.55     15906\n\n***** Ridge Regression *****\n              precision    recall  f1-score   support\n\n           0       0.64      0.90      0.75      9661\n           1       0.57      0.21      0.30      6245\n\n    accuracy                           0.63     15906\n   macro avg       0.61      0.55      0.53     15906\nweighted avg       0.61      0.63      0.57     15906\n\n***** Decision Tree *****\n              precision    recall  f1-score   support\n\n           0       0.77      0.76      0.76      9661\n           1       0.64      0.65      0.64      6245\n\n    accuracy                           0.72     15906\n   macro avg       0.70      0.70      0.70     15906\nweighted avg       0.72      0.72      0.72     15906\n\n***** Naive Bayes *****\n              precision    recall  f1-score   support\n\n           0       0.72      0.43      0.54      9661\n           1       0.46      0.74      0.56      6245\n\n    accuracy                           0.55     15906\n   macro avg       0.59      0.58      0.55     15906\nweighted avg       0.62      0.55      0.55     15906\n\n***** Neural Network *****\n              precision    recall  f1-score   support\n\n           0       0.62      0.97      0.76      9661\n           1       0.66      0.09      0.15      6245\n\n    accuracy                           0.62     15906\n   macro avg       0.64      0.53      0.46     15906\nweighted avg       0.64      0.62      0.52     15906\n\n***** XGBClassifier *****\n              precision    recall  f1-score   support\n\n           0       0.71      0.86      0.78      9661\n           1       0.68      0.46      0.54      6245\n\n    accuracy                           0.70     15906\n   macro avg       0.69      0.66      0.66     15906\nweighted avg       0.70      0.70      0.69     15906\n\n***** Support Vector Machines *****\n              precision    recall  f1-score   support\n\n           0       0.61      1.00      0.76      9661\n           1       0.00      0.00      0.00      6245\n\n    accuracy                           0.61     15906\n   macro avg       0.30      0.50      0.38     15906\nweighted avg       0.37      0.61      0.46     15906\n\n***** KNeighborsClassifier *****\n              precision    recall  f1-score   support\n\n           0       0.73      0.76      0.75      9661\n           1       0.60      0.56      0.58      6245\n\n    accuracy                           0.68     15906\n   macro avg       0.67      0.66      0.66     15906\nweighted avg       0.68      0.68      0.68     15906\n\n***** GradientBoostingClassifier *****\n              precision    recall  f1-score   support\n\n           0       0.66      0.89      0.76      9661\n           1       0.63      0.30      0.41      6245\n\n    accuracy                           0.66     15906\n   macro avg       0.65      0.59      0.58     15906\nweighted avg       0.65      0.66      0.62     15906\n\n***** RandomForestClassifier *****\n              precision    recall  f1-score   support\n\n           0       0.76      0.89      0.82      9661\n           1       0.77      0.56      0.65      6245\n\n    accuracy                           0.76     15906\n   macro avg       0.76      0.73      0.73     15906\nweighted avg       0.76      0.76      0.75     15906\n\n","output_type":"stream"}]},{"cell_type":"code","source":"clf = RandomForestClassifier(n_estimators=200, class_weight='balanced_subsample', random_state=42)\ncv  = StratifiedKFold(shuffle=True, random_state=42)\n\nscores = cross_val_score(clf, x, y, cv=cv, scoring='accuracy')\nprint(f'Scores mean: {np.mean(scores):.4f}')","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:15:49.008185Z","iopub.execute_input":"2023-02-26T17:15:49.008521Z","iopub.status.idle":"2023-02-26T17:17:29.969047Z","shell.execute_reply.started":"2023-02-26T17:15:49.008488Z","shell.execute_reply":"2023-02-26T17:17:29.967256Z"},"trusted":true},"execution_count":122,"outputs":[{"name":"stdout","text":"Scores mean: 0.7718\n","output_type":"stream"}]},{"cell_type":"code","source":"test_x = df[df['moved_after_2019'].isnull()]\ntest_x.drop(['moved_after_2019'], inplace=True, axis=1)\n\n\nlist = ['work_exp','last_date']\n\nfor i in list:\n    \n    test_x[i] = test_x[i].astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:19:13.933802Z","iopub.execute_input":"2023-02-26T17:19:13.934135Z","iopub.status.idle":"2023-02-26T17:19:13.952309Z","shell.execute_reply.started":"2023-02-26T17:19:13.934111Z","shell.execute_reply":"2023-02-26T17:19:13.951242Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"# Create Random Forest Classifier object, train it and make predicitons\nrandom_forest_model = RandomForestClassifier()\nrandom_forest_model.fit(x,y)\nsubmission.loc[test_x.index, \"moved_after_2019\"] = random_forest_model.predict(test_x)\nsubmission[\"moved_after_2019\"] = submission[\"moved_after_2019\"].astype(int)\nsubmission[\"moved_after_2019\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:19:16.665103Z","iopub.execute_input":"2023-02-26T17:19:16.665471Z","iopub.status.idle":"2023-02-26T17:19:28.109787Z","shell.execute_reply.started":"2023-02-26T17:19:16.665446Z","shell.execute_reply":"2023-02-26T17:19:28.108070Z"},"trusted":true},"execution_count":125,"outputs":[{"execution_count":125,"output_type":"execute_result","data":{"text/plain":"0    9263\n1    3992\nName: moved_after_2019, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-02-26T17:20:21.076091Z","iopub.execute_input":"2023-02-26T17:20:21.076470Z","iopub.status.idle":"2023-02-26T17:20:21.094868Z","shell.execute_reply.started":"2023-02-26T17:20:21.076443Z","shell.execute_reply":"2023-02-26T17:20:21.093322Z"},"trusted":true},"execution_count":126,"outputs":[]}]}